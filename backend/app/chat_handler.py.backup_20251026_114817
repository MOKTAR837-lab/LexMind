import os
import requests
from typing import List, Dict, Optional
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient

class ChatHandler:
    def __init__(self, engine: Optional = None):
        self.engine = engine
        self.ollama_url = "http://localhost:11434/api/generate"
        self.model = "mistral"
        
        print("Initialisation ChatHandler RAG...")
        
        try:
            self.embedding_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
            self.qdrant_client = QdrantClient(host="localhost", port=6333)
            self.collection_name = "legal_folders"
            info = self.qdrant_client.get_collection(collection_name=self.collection_name)
            print(f"RAG OK ({info.points_count} vecteurs)")
            self.use_rag = True
        except Exception as e:
            print(f"RAG non disponible: {e}")
            self.use_rag = False
        
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            self.use_ollama = response.status_code == 200
            if self.use_ollama:
                print(f"Ollama OK (modele: {self.model})")
        except:
            self.use_ollama = False
        
        print(f"ChatHandler pret ! (RAG: {self.use_rag}, Ollama: {self.use_ollama})")
    
    async def process_message(self, user_message: str, folders: List[Dict]) -> str:
        if self.use_rag and self.use_ollama:
            return await self._process_with_rag(user_message)
        elif self.use_rag:
            return self._process_rag_only(user_message)
        else:
            return self._process_basic(user_message, folders)
    
    async def _process_with_rag(self, user_message: str) -> str:
        try:
            relevant_docs = self._vector_search(user_message, top_k=10)
            
            if not relevant_docs:
                return "Aucun dossier pertinent trouve."
            
            context = "\n".join([f"{i+1}. {doc['name']} (score: {doc['score']:.2f})" 
                                for i, doc in enumerate(relevant_docs[:10])])
            
            prompt = f"""Tu es un assistant juridique pour LegalMind.

DOSSIERS PERTINENTS:
{context}

QUESTION: {user_message}

INSTRUCTIONS:
- Reponds de maniere professionnelle
- Cite les noms des dossiers pertinents
- Sois concis (max 400 mots)

REPONSE:"""

            response = requests.post(
                self.ollama_url,
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.7, "num_predict": 600}
                },
                timeout=45
            )
            
            if response.status_code == 200:
                answer = response.json().get("response", "")
                sources = self._format_sources(relevant_docs[:5])
                return f"{answer}\n\n{sources}"
            else:
                return self._process_rag_only(user_message)
                
        except Exception as e:
            return f"Erreur: {str(e)}"
    
    def _process_rag_only(self, user_message: str) -> str:
        relevant_docs = self._vector_search(user_message, top_k=15)
        
        if not relevant_docs:
            return "Aucun dossier correspondant."
        
        categories = {}
        for doc in relevant_docs:
            name = doc['name'].lower()
            if 'plainte' in name:
                categories.setdefault('Plaintes', []).append(doc)
            elif 'argumentaire' in name:
                categories.setdefault('Argumentaires', []).append(doc)
            elif 'vulnerabilite' in name or 'vulnérabilité' in name:
                categories.setdefault('Vulnerabilite', []).append(doc)
            elif 'fraude' in name:
                categories.setdefault('Fraudes', []).append(doc)
        
        response = f"Analyse de {len(relevant_docs)} dossiers pertinents:\n\n"
        for cat, docs in categories.items():
            response += f"{cat} ({len(docs)}):\n"
            for doc in docs[:5]:
                response += f"  - {doc['name']}\n"
            response += "\n"
        
        return response.strip()
    
    def _process_basic(self, user_message: str, folders: List[Dict]) -> str:
        msg_lower = user_message.lower()
        
        if "bonjour" in msg_lower or "salut" in msg_lower:
            return f"Bonjour ! Assistant LegalMind. {len(folders)} dossiers disponibles."
        
        if "combien" in msg_lower:
            return f"Vous avez {len(folders)} dossiers."
        
        return f"{len(folders)} dossiers disponibles. Posez vos questions !"
    
    def _vector_search(self, query: str, top_k=10) -> List[Dict]:
        if not self.use_rag:
            return []
        
        try:
            query_vector = self.embedding_model.encode(query)
            results = self.qdrant_client.query_points(
                collection_name=self.collection_name,
                query=query_vector.tolist(),
                limit=top_k,
                score_threshold=0.3
            )
            
            return [{
                'id': hit.id,
                'name': hit.payload.get('name', ''),
                'score': hit.score
            } for hit in results.points]
        except Exception as e:
            print(f"Erreur recherche: {e}")
            return []
    
    def _format_sources(self, docs: List[Dict]) -> str:
        if not docs:
            return ""
        
        sources = "Sources consultees:\n"
        for i, doc in enumerate(docs, 1):
            sources += f"  [{i}] {doc['name']}\n"
        
        return sources